<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Architecture Decisions: Cloud Composer vs Vertex AI Pipelines - Sonika Janagill</title>
    <meta name="description" content="A practical decision framework for choosing between Cloud Composer and Vertex AI Pipelines. Learn when to use each tool, hybrid patterns, and real-world case studies.">
    <meta name="author" content="Sonika Janagill">
    <meta name="keywords" content="MLOps, Cloud Composer, Vertex AI Pipelines, Google Cloud, Apache Airflow, Kubeflow Pipelines, Architecture, AI/ML, MLOps in 2025">

    <!-- Security Headers -->
    <meta http-equiv="X-Content-Type-Options" content="nosniff">
    <meta http-equiv="X-Frame-Options" content="DENY">
    <meta http-equiv="Referrer-Policy" content="strict-origin-when-cross-origin">
    <meta name="referrer" content="strict-origin-when-cross-origin">

    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Architecture Decisions: Cloud Composer vs Vertex AI Pipelines">
    <meta property="og:description" content="A practical decision framework for choosing between Cloud Composer and Vertex AI Pipelines. Learn when to use each tool, hybrid patterns, and real-world case studies.">
    <meta property="og:url" content="https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/">
    
    <!-- Styles -->
    <link rel="stylesheet" href="../../styles.css">
    <link rel="stylesheet" href="../article-styles.css">
</head>
<body>
    <!-- Navigation -->
    <nav>
        <div class="nav-container">
            <a href="/" class="nav-logo">
                <img src="../../img/Sonika-Logo-Light.jpeg" alt="Sonika Janagill" class="logo-light">
                <img src="../../img/Sonika-Logo-Dark.jpeg" alt="Sonika Janagill" class="logo-dark">
                <span class="nav-home-text">Home</span>
            </a>
            <ul class="nav-links">
                <li><a href="/about.html">About</a></li>
                <li><a href="/articles/">Articles</a></li>
                <li><a href="/contact.html">Contact</a></li>
                <li>
                    <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">
                        <img src="../../img/Sun.png" alt="Light mode" class="theme-icon theme-icon-light">
                        <img src="../../img/Moon.png" alt="Dark mode" class="theme-icon theme-icon-dark">
                    </button>
                </li>
            </ul>
        </div>
    </nav>

    <!-- Blog Header -->
    <header class="blog-header">
        <div class="container">
            <div class="blog-header-left">
                <div class="blog-header-tags">
                    <a href="/articles/?tag=MLOps" class="blog-header-tag">#MLOps</a>
                    <a href="/articles/?tag=AI/ML" class="blog-header-tag">#AI/ML</a>
                </div>
                <h2>MLOps Architecture Decisions</h2>
                <p class="blog-subtitle">Cloud Composer vs Vertex AI Pipelines</p>

            <div class="blog-header-right">
                <div class="blog-meta">
                    <div class="blog-meta-item">
                        <span>October 2025</span>
                    </div>
                    <div class="blog-meta-item">
                        <span>10 min read</span>
                    </div>
                </div>
                <div class="blog-share-buttons">
                    <a href="https://x.com/intent/tweet?url=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/" class="blog-share-btn" title="Share on X" target="_blank" rel="noopener noreferrer">
                        <img src="../../img/x-icon.png" alt="X">
                    </a>
                    <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/" class="blog-share-btn" title="Share on LinkedIn" target="_blank" rel="noopener noreferrer">
                        <img src="../../img/linkedin-icon.png" alt="LinkedIn">
                    </a>
                    <a href="mailto:?subject=Check out this article&body=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/" class="blog-share-btn" title="Share via Email">
                        <img src="../../img/email-icon.png" alt="Email">
                    </a>
                    <button onclick="copyShareLink(this)" class="blog-share-btn" title="Copy link">
                        <img src="../../img/copy-icon.png" alt="Copy">
                    </button>
                </div>
            </div>
            </div>
        </div>
    </header>

    <div style="margin: 0.5rem 0; text-align: center;">
        <img src="../../img/ComposerVsVertexAI.png" alt="The native Vertex AI Pipelines visualiser automatically creates this execution graph, showing the conditional deployment workflow. Note how model evaluation determines which path executes - only models with accuracy > 0.85 proceed to endpoint creation and deployment." style="max-width: 40%; height: auto; border-radius: var(--radius-lg);">
        <p style="text-align: center;">Image generated using <a href="https://gemini.google.com/">Gemini</a></p>
    </div>

    <!-- Blog Content -->
    <main class="blog-content">
        <p><strong>Your team just got budget approval for MLOps infrastructure. The architect recommends Cloud Composer for large-scale data ingestion to support your new Gemini model fine-tuning pipeline. The ML engineers want Vertex AI Pipelines for experiment tracking and model evaluation. The data engineers are confused. Sound familiar?</strong></p>

        <p>This internal debate is one of the most common and critical crossroads in building a modern ML platform on Google Cloud. The stakes are high. The wrong choice can lead to six months of technical debt, frustrated teams, and a platform that fights your workflow instead of enabling it. The right choice, however, lays the foundation for a scalable, maintainable ML system for years to come.</p>

        <p>Too often, this decision is made based on team familiarity or feature-list buzzwords, not a clear-eyed assessment of actual needs. This article provides a practical decision framework that prioritises team skills, data complexity, and long-term budget—helping you move beyond the hype to an architecture that truly fits.</p>

        <div class="key-concept">
            <p><b>Companion Resources:</b> Full working examples and Terraform configurations available at <a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines">github.com/sonikajanagill/composer-vs-vertex-ai-pipelines</a></p>
        </div>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>The Enterprise Dilemma</h2>

        <p>Choosing between Cloud Composer and Vertex AI Pipelines is about more than just picking a tool; it's a fundamental decision that will shape your engineering culture, team dynamics, and operational efficiency.</p>

        <h3>Why This Decision Matters</h3>

        <p>The tool you select becomes the backbone of your data and ML operations. Cloud Composer, as a managed Apache Airflow service, brings powerful, general-purpose workflow orchestration. Vertex AI Pipelines, a fully managed Kubeflow Pipelines (KFP) service, offers a native, ML-centric environment.</p>

        <p><b>Migration costs can be 10x the initial setup</b>, involving not just technology but retraining teams and re-architecting processes. Developer experience and skill-set alignment prove more critical than raw feature completeness.</p>

        <h3>Common Decision Patterns (Good and Bad)</h3>

        <p>✘ <strong>Comfort-First</strong>: "We know Airflow, so Composer" ignores ML-specific needs, leading to custom experiment tracking development.</p>
        <p>✘ <strong>Feature-First</strong>: "ML team wants Vertex AI" backfires when most work involves complex data engineering outside the Vertex AI ecosystem.</p>
        <p>✔ <strong>Requirements-First</strong>: Match tool capabilities to actual workflow complexity—data plumbing vs. ML experimentation.</p>

        <h3><a href="https://docs.cloud.google.com/vertex-ai/generative-ai/docs">Generative AI integration on Vertex AI</a></h3>

        <p>The landscape has evolved dramatically with the rise of large language models:</p>

        <table>
            <tr>
                <th>Capability</th>
                <th>Cloud Composer</th>
                <th>Vertex AI Pipelines</th>
            </tr>
            <tr>
                <td><strong>Gemini Integration</strong></td>
                <td>Custom operators required</td>
                <td>✔ Native Gemini components</td>
            </tr>
            <tr>
                <td><strong>RAG Pipelines</strong></td>
                <td>Manual implementation</td>
                <td>✔ Pre-built RAG components</td>
            </tr>
            <tr>
                <td><strong>Vector Embeddings</strong></td>
                <td>External orchestration</td>
                <td>✔ Built-in Vertex AI Vector Search</td>
            </tr>
            <tr>
                <td><strong>LLM Fine-tuning</strong></td>
                <td>Custom workflow design</td>
                <td>✔ Integrated tuning pipelines</td>
            </tr>
            <tr>
                <td><strong>Multi-modal AI</strong></td>
                <td>Complex DAG orchestration</td>
                <td>✔ Native multi-modal support</td>
            </tr>
        </table>

        <div class="key-concept">
            <p>For teams building LLM applications in 2025, Vertex AI Pipelines offers significant architectural advantages through native integration with Gemini, Vector Search, and Foundation Models.</p>
        </div>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Composer's Sweet Spot: Macro Pipeline Domain</h2>

        <p>Cloud Composer is your go-to choice for <strong>macro-orchestration</strong>—managing complex, multi-system workflows where ML is just one part of a larger business process.</p>

        <h3>When Composer Excels</h3>

        <ol>
            <li><strong>Complex Data Orchestration</strong>: Composer shines when your pipeline is a symphony of diverse systems. This includes integrating legacy on-premises databases with cloud services, managing dependencies on external APIs, blending ML workloads with traditional ETL or business intelligence tasks, and building robust, auditable regulatory compliance workflows.</li>
            <li><strong>Team Profile Match</strong>: Composer is a natural fit if your team has strong data engineering chops, existing Airflow knowledge, a culture of infrastructure-as-code (e.g., Terraform), and relies heavily on SQL and scripting for data processing.</li>
            <li><strong>Architecture Patterns</strong>: Typical patterns include orchestrating the entire flow from a data lake to a feature store, then triggering a model training job. It's ideal for batch-processing-heavy environments and scenarios requiring extensive coordination with external systems for governance and compliance.</li>
        </ol>

        <h3>Implementation Example</h3>

        <p>The following DAG (<a href="https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html">Directed Acyclic Graph</a>) snippet illustrates how Composer acts as the central conductor, handling data extraction, quality checks, and finally triggering a specialised ML pipeline on Vertex AI.</p>

        <div class="code-block-header">
            <span>Python - Composer DAG</span>
            <div class="code-block-actions">
                <button class="code-btn" onclick="copyCode(this)">📋 Copy</button>
                <button class="code-btn"><a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines" target="_blank" rel="noopener noreferrer">🔗 GitHub</a></button>
            </div>
        </div>
        <pre><code class="language-python"># Composer DAG structure for enterprise ML
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.providers.google.cloud.operators.vertex_ai.custom_job import CreateCustomTrainingJobOperator

dag = DAG('enterprise_ml_pipeline', schedule_interval='@weekly')

# Data extraction and validation pipeline
extract_sources = BashOperator(task_id='extract_multi_source_data', 
                            bash_command='gsutil -m cp gs://data-lake/* gs://staging/', dag=dag)
validate_data = PythonOperator(task_id='validate_data_quality', 
                            python_callable=validate_schema_and_quality, dag=dag)

# Trigger specialised ML pipeline
trigger_vertex_training = CreateCustomTrainingJobOperator(
    task_id='start_vertex_ai_pipeline',
    staging_bucket='gs://your-bucket/staging',
    display_name='ml-training-pipeline',
    container_uri='us-docker.pkg.dev/your-project/ml-trainer:latest',  # Updated to Artifact Registry
    machine_type='e2-standard-4',  # Updated machine type
    replica_count=1,
    dag=dag
)

# Define task dependencies
extract_sources >> validate_data >> trigger_vertex_training</code></pre>
        <p>Reference: <a href="https://airflow.apache.org/docs/apache-airflow-providers-google/6.4.0/_api/airflow/providers/google/cloud/operators/vertex_ai/custom_job/index.html">CreateCustomTrainingJobOperator</a>.</p>

        <h3>Cost & Performance Reality</h3>

        <p>From my experience with enterprise deployments:</p>
        <ul>
            <li><strong>Setup Complexity</strong>: Medium - while Airflow infrastructure is managed, designing robust DAGs requires careful planning and testing.</li>
            <li><strong>Ongoing Maintenance</strong>: Low operational overhead since Google manages the underlying infrastructure, but your team owns DAG code, dependency management, and scaling configurations.</li>
            <li><strong>Cost Structure</strong>: Predictable monthly costs starting around $200–500 for small environments. This makes it suitable for always-on workflows where you need consistent orchestration capability.</li>
            <li><strong>Learning Curve</strong>: Steep for teams without Airflow experience, but manageable for seasoned data engineers who understand workflow orchestration concepts.</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Vertex AI Pipelines' Sweet Spot: Micro Pipeline Domain</h2>

        <p>Vertex AI Pipelines specialises in <strong>micro-orchestration</strong> of machine learning workflows with deep, native understanding of ML concepts.</p>

        <h3>When Vertex AI Pipelines Excels</h3>

        <ol>
            <li><strong>ML-Native Workflows</strong>: Built-in experiment tracking, model versioning, hyperparameter optimisation, and A/B testing infrastructure.</li>
            <li><strong>Team Profile Match</strong>: ML Engineers and Data Scientists with Python-first culture, containerisation comfort, rapid research-to-production focus.</li>
            <li><strong>Architecture Patterns</strong>: Feature engineering → training → evaluation → deployment loop, experiment-heavy environments, component reusability priority.</li>
        </ol>

        <div style="margin: 2rem 0; text-align: center;">
            <img src="../../img/vertexai_example.jpg" alt="Vertex AI Pipelines example showing ML workflow with experiment tracking, model versioning, and native Vertex AI integration for rapid experimentation and production deployment." style="max-width: 100%; height: auto; border-radius: var(--radius-lg);">
        </div>

        <div class="key-concept">
            <p>It's crucial to understand that Vertex AI Pipelines is <strong>Kubeflow Pipelines (KFP) fully managed by Google</strong>. You get the full power and flexibility of KFP for defining complex ML workflows, with all the Kubernetes operational overhead completely abstracted away.</p>
        </div>

        <h3>Implementation Example</h3>

        <p>This Python code defines a pipeline component and orchestrates a full ML lifecycle, leveraging built-in Vertex AI components for evaluation and deployment.</p>

        <div class="code-block-header">
            <span>Python - Vertex AI Pipeline Component</span>
            <div class="code-block-actions">
                <button class="code-btn" onclick="copyCode(this)">📋 Copy</button>
                <button class="code-btn"><a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines" target="_blank" rel="noopener noreferrer">🔗 GitHub</a></button>
            </div>
        </div>
        <pre><code class="language-python">from kfp import dsl
from google.cloud.aiplatform import PipelineJob
from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationOp

@dsl.component(base_image="us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-13:latest")
def train_model(dataset_path: str, model_output_path: str, hyperparameters: dict) -> tuple[str, float]:
    """Train ML model with native Vertex AI experiment tracking"""
    from google.cloud import aiplatform
    
    with aiplatform.start_run(run="training-run") as run:
        model = train_with_vertex_ai(dataset_path, hyperparameters)
        accuracy = evaluate_model(model)
        
        # Native experiment tracking
        run.log_metrics({"accuracy": accuracy, "loss": model.loss})
        run.log_params(hyperparameters)
        
        model_resource = aiplatform.Model.upload(
            display_name="ml-model",
            artifact_uri=model_output_path,
            serving_container_image_uri="us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-13:latest"
        )
    return model_resource.resource_name, accuracy

@dsl.pipeline(name="ml-training-pipeline")
def ml_pipeline(dataset_path: str, hyperparameters: dict):
    train_task = train_model(dataset_path=dataset_path, hyperparameters=hyperparameters)
    
    # Built-in evaluation with zero configuration
    eval_task = ModelEvaluationOp(
        project="your-project",
        model=train_task.outputs["model_resource_name"],
        target_field_name="target",
        prediction_type="classification"
    )</code></pre>
        <div class="key-concept">
            <p><strong>Reusable Components</strong>: The <code>@dsl.component</code> decorator creates a containerised, reusable pipeline step with explicit input/output typing. This enables team collaboration, reusability across pipelines, and component versioning. Reference: <a href="https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline">https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline</a>.</p>
            <p><strong>Native Vertex AI Integration</strong>: Built-in Vertex AI components deliver zero-config evaluation, managed infrastructure, experiment integration, and production readiness with built-in model governance. Reference: <a href="https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list">https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list</a>.</p>
        </div>

        <h3>Cost & Performance Reality</h3>

        <p>Based on projects I've worked on:</p>
        <ul>
            <li><strong>Setup Complexity</strong>: Low - you define pipelines in Python and submit them. No cluster provisioning or infrastructure management required.</li>
            <li><strong>Ongoing Maintenance</strong>: Very low since Google manages the underlying Kubernetes infrastructure. You only maintain pipeline and component definitions.</li>
            <li><strong>Cost Structure</strong>: Pay-per-use model with approximately $0.03 per pipeline run plus compute costs. This can be significantly cheaper for sporadic training jobs, but costs add up with frequent experimentation.</li>
            <li><strong>Learning Curve</strong>: Moderate - the barrier is conceptual (understanding components, pipelines, and containerisation) rather than infrastructural.</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Comprehensive Decision Framework</h2>

        <p>Based on my experience across different team compositions:</p>
        <h3><strong>Team Skill and Cost Considerations</strong></h3>

        <table>
            <tr>
                <th>Skill Area</th>
                <th>Cloud Composer</th>
                <th>Vertex AI Pipelines</th>
            </tr>
            <tr>
                <td><strong>Data Engineering</strong></td>
                <td>✔ Airflow expertise advantage</td>
                <td>⚠ New concepts to learn</td>
            </tr>
            <tr>
                <td><strong>ML Engineering</strong></td>
                <td>⚠ Limited native ML features</td>
                <td>✔ Native Vertex AI integration</td>
            </tr>
            <tr>
                <td><strong>Python Development</strong></td>
                <td>✔ DAG development skills</td>
                <td>✔ Component development skills</td>
            </tr>
            <tr>
                <td><strong>Infrastructure Management</strong></td>
                <td>⚠ DAG dependency management</td>
                <td>✔ Fully managed simplicity</td>
            </tr>
            <tr>
                <td><strong>Generative AI/LLMs</strong></td>
                <td>✘ Manual integration required</td>
                <td>✔ Native Gemini components</td>
            </tr>
            <tr>
                <td><strong>Security & Compliance</strong></td>
                <td>✔ Full audit trail control</td>
                <td>✔ Built-in governance features</td>
            </tr>
        </table>

        <h3>Cost Reality Check</h3>
        <p><strong>Small Teams (2–5 engineers):</strong> Vertex AI Pipelines typically offer better cost efficiency due to a pay-per-use model, especially for experimental workloads.</p>
        <p><strong>Medium Teams (5–15 engineers):</strong> Costs become more comparable; tool choice should focus on team skills and workflow complexity.</p>
        <p><strong>Large Teams (15+ engineers):</strong> Hybrid approaches often provide the best balance, using each tool for its strengths.</p>
        <p><i>Cost estimates based on personal experience with enterprise deployments and publicly available Google Cloud pricing.</i></p>

        <h3>Security Considerations</h3>
        <p>Both platforms provide enterprise-grade security, but with different approaches:</p>
        <ul>
            <li><strong>Identity & Access Management:</strong>
                <ul>
                    <li>Composer: Granular DAG-level permissions, manual service account management</li>
                    <li>Vertex AI Pipelines: Component-level IAM with automatic service account propagation</li>
                </ul>
            </li>
            <li><strong>Network Security:</strong>
                <ul>
                    <li>Composer: Full control over VPC configuration and custom networking</li>
                    <li>Vertex AI Pipelines: Managed VPC with automatic private endpoint setup</li>
                </ul>
            </li>
            <li><strong>Audit & Compliance:</strong>
                <ul>
                    <li>Composer: Complete task lineage through Cloud Logging, custom audit implementations</li>
                    <li>Vertex AI Pipelines: Built-in ML governance and automatic artifact lineage</li>
                </ul>
            </li>
        </ul>
        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Migration Strategies & Performance Benchmarks</h2>

        <h3>Migration Approaches</h3>
        <p><strong>From Composer to Vertex AI Pipelines:</strong> In my experience, this migration typically takes 2–4 months, depending on DAG complexity. The main challenges involve:</p>
        <ul>
            <li>Converting Python operators to containerised components</li>
            <li>Migrating custom experiment tracking to Vertex AI Experiments</li>
            <li>Retraining teams on KFP concepts</li>
        </ul>

        <p><strong>From Vertex AI Pipelines to Composer:</strong> This path is more complex (3–6 months) because you're moving from managed simplicity to infrastructure management:</p>
        <ul>
            <li>Building custom operators for ML components</li>
            <li>Implementing experiment tracking systems</li>
            <li>Setting up proper DAG orchestration for component dependencies</li>
        </ul>

        <h3>Common Troubleshooting Patterns</h3>
        <p><strong>Composer Issues I've Encountered:</strong></p>
        <ul>
            <li><strong>DAG Import Failures:</strong> Usually due to missing dependencies or import errors</li>
            <div class="code-block-header">
            <span>Python - Error Handling</span>
            <div class="code-block-actions">
                <button class="code-btn" onclick="copyCode(this)">📋 Copy</button>
            </div>
        </div>
        <pre><code class="language-python">try:
    from airflow.providers.google.cloud.operators.vertex_ai import CreateCustomTrainingJobOperator
except ImportError as e:
    logging.error(f"Missing dependency: {e}")
    raise</code></pre>
            <li><strong>Resource Contention:</strong> Monitor Airflow scheduler and worker resources. Implement DAG-level concurrency controls. Use pool-based resource management.</li>
            <li><strong>Dependency Conflicts:</strong> Use virtual environments for Python dependencies. Implement proper DAG testing in CI/CD. Version pin all dependencies.</li>
        </ul>

        <p><strong>Vertex AI Pipelines Common Problems:</strong></p>
        <ul>
            <li><strong>Component Definition Errors:</strong> Often missing type annotations or improper input/output specifications</li>
            <div class="code-block-header">
            <span>Python - Component Type Hints</span>
            <div class="code-block-actions">
                <button class="code-btn" onclick="copyCode(this)">📋 Copy</button>
            </div>
        </div>
        <pre><code class="language-python"># ✘ Missing type hint
@dsl.component
def bad_component(data):
    return process_data(data)

# ✔ Proper typing
@dsl.component  
def good_component(data: str) -> str:
    return process_data(data)</code></pre>
            <li><strong>Pipeline Compilation Failures</strong>: Validate component inputs/outputs match. Check for circular dependencies. Ensure proper parameter passing.</li>
            <li><strong>Resource Allocation Issues</strong>: Monitor component resource requests vs. limits. Implement proper auto-scaling configuration. Use appropriate machine types for workloads.</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Hybrid Architecture Implementation</h2>

        <p>For enterprises requiring both macro and micro orchestration, a hybrid approach leverages each tool's strengths through clear service boundaries.</p>

        <h3>Implementation Pattern</h3>

        <div class="code-block-header">
            <span>Python - Hybrid Integration Pattern</span>
            <div class="code-block-actions">
                <button class="code-btn" onclick="copyCode(this)">📋 Copy</button>
            </div>
        </div>
        <pre><code class="language-python"># Composer DAG triggers Vertex AI Pipeline
from airflow.providers.google.cloud.operators.vertex_ai.pipeline_job import CreatePipelineJobOperator

trigger_ml_pipeline = CreatePipelineJobOperator(
    task_id="trigger_vertex_pipeline",
    display_name="ml-training-workflow",
    template_path="gs://your-bucket/pipeline.json",
    parameter_values={
        "dataset_path": "{{ task_instance.xcom_pull(task_ids='data_validation') }}",
        "model_name": "recommendation-model-{{ ds }}"
    },
    dag=dag
)

# Vertex AI Pipeline signals back via Cloud Storage
@dsl.component
def signal_completion(model_uri: str, accuracy: float):
    """Signal pipeline completion back to Composer"""
    import json
    from google.cloud import storage
    
    client = storage.Client()
    bucket = client.bucket("pipeline-coordination")
    blob = bucket.blob("ml-pipeline-complete.json")
    
    result = {
        "model_uri": model_uri,
        "accuracy": accuracy,
        "timestamp": datetime.utcnow().isoformat(),
        "status": "completed"
    }
    blob.upload_from_string(json.dumps(result))</code></pre>

        <p>The hybrid architecture follows this flow:</p>
        <div style="margin: 2rem 0; text-align: center;">
            <img src="../../img/vertexai_full_pipeline.png" alt="Vertex AI Pipelines example showing ML workflow with experiment tracking, model versioning, and native Vertex AI integration for rapid experimentation and production deployment." style="max-width: 100%; height: auto; border-radius: var(--radius-lg);">
        </div>

        <h3>Cost Optimisation Strategy</h3>
        <p>From enterprise implementations I've observed:</p>

        <ul>
            <li><strong>Predictable Base Costs</strong>: Use Composer for always-on data workflows ($400-600/month baseline)</li>
            <li><strong>Variable ML Costs</strong>: Leverage Vertex AI Pipelines for experiment-heavy workloads (pay-per-use scaling)</li>
            <li><strong>Total Cost Optimisation</strong>: 40-60% cost reduction vs. single-tool approaches in enterprise scenarios</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Real-World Case Studies</h2>

        <h3>Case Study 1: E-commerce Recommendation (Hybrid Success)</h3>

        <ul>
            <li><strong>Architecture</strong>: Composer for data orchestration + Vertex AI for ML experimentation</li>
            <li><strong>Outcome</strong>: 40% faster ML iteration, 60% infrastructure cost reduction</li>
            <li><strong>Key Lesson</strong>: Service boundary separation enabled independent team scaling</li>
        </ul>

        <h3>Case Study 2: Financial Compliance (Composer-Only)</h3>

        <ul>
            <li><strong>Architecture</strong>: End-to-end Airflow DAGs for audit trail requirements</li>
            <li><strong>Outcome</strong>: Complete regulatory compliance, simplified audit processes</li>
            <li><strong>Key Lesson</strong>: Regulatory constraints often override technical preferences</li>
        </ul>

        <h3>Case Study 3: Healthcare AI (Research-to-Production Pipeline)</h3>

        <ul>
            <li><strong>Architecture</strong>: Vertex AI for research, Composer for production deployment</li>
            <li><strong>Outcome</strong>: 10x faster research iteration, robust production reliability</li>
            <li><strong>Key Lesson</strong>: Different phases of ML lifecycle benefit from specialised tools</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Implementation Decision Checklist</h2>

        <h3>Quick Decision Tree</h3>

        <div style="margin: 2rem 0; border-radius: var(--radius-lg); overflow: hidden; border: 1px solid var(--border);">
            <iframe style="border: none; width: 100%; height: 700px;" 
                    src="https://whoop-leaves-14036682.figma.site/" 
                    allowfullscreen>
            </iframe>
        </div>

        <h3>Red Flags</h3>

        <ul>
            <li><strong>Avoid Composer if</strong>: ML-heavy team, experiment tracking critical, native Vertex AI integration required</li>
            <li><strong>Avoid Vertex AI Pipelines if</strong>: Limited Python ML skills, extensive non-Google integrations, complex business process orchestration</li>
            <li><strong>Consider Hybrid if</strong>: Clear separation between data/business logic and ML experimentation</li>
        </ul>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <h2>Strategic Implementation Approach</h2>

        <h3>The Generative AI Reality</h3>

        <p>With the rapid evolution of LLMs and multimodal AI, <strong>Vertex AI Pipelines has gained significant strategic advantage</strong> through native integration with Google's AI ecosystem. Teams building on Gemini, RAG, or advanced AI applications should strongly consider this path.</p>

        <h3>Implementation Strategy</h3>

        <ol>
            <li><strong>Start with Primary Pain Point</strong>: Address your biggest workflow challenge first</li>
            <li><strong>Plan for Evolution</strong>: Both tools can coexist; start simple, scale strategically</li>
            <li><strong>Measure Outcomes</strong>: Track developer velocity, cost efficiency, and team satisfaction</li>
            <li><strong>Embrace Hybrid</strong>: Most enterprises benefit from specialised tools for specialised problems</li>
        </ol>

        <h3>Success Metrics That Matter</h3>

        <ul>
            <li><strong>Developer Velocity</strong>: Idea to production timeline</li>
            <li><strong>System Reliability</strong>: Pipeline success rates >95%</li>
            <li><strong>Cost Efficiency</strong>: Total ownership cost per model</li>
            <li><strong>Team Adoption</strong>: Active usage rates >80%</li>
        </ul>
        
        <div class="key-concept">
            <p><strong>Remember</strong>: The best architecture is the one your team actually uses and maintains successfully. Technical elegance means nothing if it's abandoned after six months.</p>
        </div>

        <hr style="margin: 2rem 0; border: none; border-top: 1px solid var(--border);">

        <!--<h2>Resources & Next Steps</h2>

        <p><strong>Companion Resources</strong>:</p>
        <ul>
            <li><a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines" target="_blank" rel="noopener noreferrer">Complete working examples and Terraform configurations</a></li>
            <li><a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines/tree/main/templates" target="_blank" rel="noopener noreferrer">Architecture decision templates and cost calculators</a></li>
        </ul>

        <p><strong>Community Discussion</strong>: Share your architecture decisions and lessons learned in the comments or <a href="https://github.com/sonikajanagill/composer-vs-vertex-ai-pipelines/discussions" target="_blank" rel="noopener noreferrer">open a GitHub discussion</a>.</p>
        -->
        <h3>Coming Next:</h3>
        <p>"Multi-Cloud Data Access: Workload Identity Federation Patterns" - diving deep into enterprise security architecture for MLOps.</p>

        <div class="article-share">
            <div class="share-title">Share this article:</div>
            <div class="share-buttons">
                <a href="https://x.com/intent/tweet?url=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/&text=Architecture%20Decisions:%20Cloud%20Composer%20vs%20Vertex%20AI%20Pipelines%20-%20A%20practical%20decision%20framework%20by%20@sonikajanagill" target="_blank" rel="noopener noreferrer" class="blog-share-btn" title="Share on X">
                    <img src="../../img/x-icon.png" alt="X">
                </a>
                <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/" target="_blank" rel="noopener noreferrer" class="blog-share-btn" title="Share on LinkedIn">
                    <img src="../../img/linkedin-icon.png" alt="LinkedIn">
                </a>
                <a href="mailto:?subject=Check out this article&body=https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/" class="blog-share-btn" title="Share via Email">
                    <img src="../../img/email-icon.png" alt="Email">
                </a>
                <button onclick="copyShareLink(this)" class="blog-share-btn" title="Copy link">
                    <img src="../../img/copy-icon.png" alt="Copy">
                </button>
            </div>
        </div>

        <p style="margin-top: 2rem; color: var(--text-tertiary); font-size: 0.9rem;">   
            Also published on <a href="https://medium.com/@sonika.janagill/cloud-composer-vs-vertex-ai-pipelines-73dcb8a39577?source=friends_link&sk=4eb8a75138dcd212a783a7b1d4935334" target="_blank" rel="noopener noreferrer">Medium</a> - Join the discussion in the comments!
        </p>
    </main>

    <footer>
        <div class="footer-content">
            <p>&copy; 2025 Sonika Janagill. All rights reserved.</p>
        </div>
    </footer>

    <script>
        // Copy share link to clipboard
        function copyShareLink(button) {
            const url = 'https://sonikajanagill.com/articles/composer-vs-vertex-ai-pipelines/';
            navigator.clipboard.writeText(url).then(() => {
                const originalText = button.innerHTML;
                button.innerHTML = '<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="20 6 9 17 4 12"></polyline></svg> Copied!';
                setTimeout(() => {
                    button.innerHTML = originalText;
                }, 2000);
            }).catch(err => {
                console.error('Failed to copy link:', err);
                alert('Failed to copy link');
            });
        }

        // Check for saved theme preference or default to dark mode
        const theme = localStorage.getItem('theme') || 'dark';
        document.documentElement.setAttribute('data-theme', theme);

        const themeToggle = document.getElementById('theme-toggle');

        // Toggle theme
        themeToggle.addEventListener('click', () => {
            const currentTheme = document.documentElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';

            document.documentElement.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
        });
    </script>
    <script src="../article-utils.js"></script>
</body>
</html>
